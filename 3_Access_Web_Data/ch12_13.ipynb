{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Web Data with Python\n",
    "\n",
    "## Chapter 12: Networked Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\n",
      "Date: Mon, 23 May 2022 12:22:52 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\n",
      "ETag: \"a7-54f6609245537\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 167\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: text/plain\n",
      "\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "# The worldâ€™s simplest web browser\n",
    "\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "# \"\\r\\n\" signifies an EOL (end of line), so \"\\r\\n\\r\\n\" signifies nothing between two EOL sequences. That is the equivalent of a blank line.\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    \n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\n",
      "Date: Mon, 23 May 2022 14:57:53 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\n",
      "ETag: \"1d3-54f6609240717\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 467\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: text/plain\n",
      "\n",
      "Why should you learn to write programs?\n",
      "\n",
      "Writing programs (or programming) is a very creative \n",
      "and rewarding activity.  You can write programs for \n",
      "many reasons, ranging from making your living to solving\n",
      "a difficult data analysis problem to having fun to helping\n",
      "someone else solve a problem.  This book assumes that \n",
      "everyone needs to know how to program, and that once \n",
      "you know how to program you will figure out what you want \n",
      "to do with your newfound skills.  \n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/intro-short.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "# \"\\r\\n\" signifies an EOL (end of line), so \"\\r\\n\\r\\n\" signifies nothing between two EOL sequences. That is the equivalent of a blank line.\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    \n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "# Retrieving Web Pages\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode(),end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "counts = dict()\n",
    "\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "        \n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>The First Page</h1>\n",
      "<p>\n",
      "If you like, you can switch to the \n",
      "<a href=\"http://www.dr-chuck.com/page2.htm\">\n",
      "Second Page</a>.\n",
      "</p>\n",
      "\n",
      "http://www.dr-chuck.com/page2.htm\n"
     ]
    }
   ],
   "source": [
    "# Parsing Web Pages\n",
    "\n",
    "# Install BeautifulSoup: pip install beautifulsoup4\n",
    "\n",
    "\n",
    "# Get all the links from a page:\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.dr-chuck.com/page1.htm'\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "print(soup)\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 50\n",
      "Sum 2440\n"
     ]
    }
   ],
   "source": [
    "# Assignment: Scraping HTML Data with BeautifulSoup\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = 'http://py4e-data.dr-chuck.net/comments_1559329.html'\n",
    "html = urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('span')\n",
    "total = 0\n",
    "for tag in tags:\n",
    "    total += int(tag.contents[0])\n",
    "\n",
    "print(f'Count {len(tags)}')\n",
    "print(f'Sum {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Montgomery.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Mhairade.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Butchi.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Anayah.html\n",
      "Anayah\n"
     ]
    }
   ],
   "source": [
    "# Assignment: Following Links in HTML Using BeautifulSoup\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# url = input('Enter URL: ')\n",
    "# count = int(input('Enter count: '))\n",
    "# position = int(input('Enter position: '))\n",
    "url = 'http://py4e-data.dr-chuck.net/known_by_Fikret.html'\n",
    "count = 4\n",
    "position = 3\n",
    "\n",
    "last_name = ''\n",
    "\n",
    "for i in range(count+1):\n",
    "    print(f'Retrieving: {url}')\n",
    "    html = urllib.request.urlopen(url, context=ctx).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup('a')\n",
    "\n",
    "    if i == count-1:\n",
    "        last_name=links[position-1].contents[0]\n",
    "    \n",
    "    url = links[position-1].get('href', None)\n",
    "\n",
    "print(last_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 13: Using Web Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Vitor\n",
      "Phone: +55 19 123456789\n",
      "Phone Attr: intl\n",
      "Email Attr: yes\n"
     ]
    }
   ],
   "source": [
    "# Parsing XML\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "data = '''\n",
    "<person>\n",
    "    <name>Vitor</name>\n",
    "    <phone type=\"intl\">+55 19 123456789</phone>\n",
    "    <email hide=\"yes\"/>\n",
    "</person>\n",
    "'''\n",
    "\n",
    "tree = ET.fromstring(data)\n",
    "print('Name:',tree.find('name').text)\n",
    "print('Phone:',tree.find('phone').text)\n",
    "print('Phone Attr:',tree.find('phone').get('type'))\n",
    "print('Email Attr:',tree.find('email').get('hide'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving http://py4e-data.dr-chuck.net/comments_305727.xml\n",
      "Retrieved 4205 characters\n",
      "Count: 50\n",
      "Sum: 2549\n"
     ]
    }
   ],
   "source": [
    "# Assignment Extracting Data from XML\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import xml.etree.ElementTree as ET\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter location: ')\n",
    "# url = 'http://py4e-data.dr-chuck.net/comments_42.xml'\n",
    "print(f'Retrieving {url}')\n",
    "\n",
    "xml = urllib.request.urlopen(url, context=ctx).read()\n",
    "print(f'Retrieved {len(xml)} characters')\n",
    "\n",
    "tree = ET.fromstring(xml)\n",
    "counts = tree.findall('.//count')\n",
    "total = 0\n",
    "for count in counts:\n",
    "    total += int(count.text)\n",
    "\n",
    "\n",
    "print(f'Count: {len(counts)}')\n",
    "print(f'Sum: {total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Chuck\n",
      "Phone: +1 734 303 4456\n",
      "Hide: yes\n"
     ]
    }
   ],
   "source": [
    "# Parsing JSON\n",
    "\n",
    "import json\n",
    "\n",
    "data = '''\n",
    "{\n",
    "  \"name\" : \"Chuck\",\n",
    "  \"phone\" : {\n",
    "    \"type\" : \"intl\",\n",
    "    \"number\" : \"+1 734 303 4456\"\n",
    "   },\n",
    "   \"email\" : {\n",
    "     \"hide\" : \"yes\"\n",
    "   }\n",
    "}\n",
    "'''\n",
    "\n",
    "info = json.loads(data)\n",
    "print('Name:', info[\"name\"])\n",
    "print('Phone:', info[\"phone\"][\"number\"])\n",
    "print('Hide:', info[\"email\"][\"hide\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User count: 2\n",
      "-----\n",
      "Name: Chuck\n",
      "Id: 001\n",
      "Attribute: 2\n",
      "-----\n",
      "Name: Brent\n",
      "Id: 009\n",
      "Attribute: 7\n"
     ]
    }
   ],
   "source": [
    "# Parsing JSON\n",
    "\n",
    "import json\n",
    "\n",
    "data = '''\n",
    "[\n",
    "  { \"id\" : \"001\",\n",
    "    \"x\" : \"2\",\n",
    "    \"name\" : \"Chuck\"\n",
    "  },\n",
    "  { \"id\" : \"009\",\n",
    "    \"x\" : \"7\",\n",
    "    \"name\" : \"Brent\"\n",
    "  }\n",
    "]'''\n",
    "\n",
    "info = json.loads(data)\n",
    "print('User count:', len(info))\n",
    "\n",
    "for item in info:\n",
    "    print(\"-----\")\n",
    "    print('Name:', item['name'])\n",
    "    print('Id:', item['id'])\n",
    "    print('Attribute:', item['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving http://py4e-data.dr-chuck.net/comments_305728.json\n",
      "Retrieved 2731 characters\n",
      "Count: 50\n",
      "Sum: 2546\n"
     ]
    }
   ],
   "source": [
    "# Calling a JSON API\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "\n",
    "url = input('Enter location: ')\n",
    "# url = 'http://py4e-data.dr-chuck.net/comments_42.json'\n",
    "print(f'Retrieving {url}')\n",
    "\n",
    "data = urllib.request.urlopen(url).read()\n",
    "print(f'Retrieved {len(data)} characters')\n",
    "\n",
    "info = json.loads(data)\n",
    "comments = info[\"comments\"]\n",
    "print(f'Count: {len(comments)}')\n",
    "\n",
    "total = 0\n",
    "for comment in comments:\n",
    "  total += int(comment['count'])\n",
    "print(f'Sum: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving http://py4e-data.dr-chuck.net/json?address=unicamp&key=42\n",
      "Retrieved 2116 characters\n",
      "Place id ChIJtU3SBbDGyJQRltcEzw5128Y\n"
     ]
    }
   ],
   "source": [
    "# Calling a JSON API\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "api_key = 42\n",
    "serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    parms = dict()\n",
    "    parms['address'] = address\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "    print(f'Retrieving {url}')\n",
    "\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    data = uh.read().decode()\n",
    "    print(f'Retrieved {len(data)} characters')\n",
    "\n",
    "    try:\n",
    "        js = json.loads(data)\n",
    "    except:\n",
    "        js = None\n",
    "\n",
    "    if not js or 'status' not in js or js['status'] != 'OK':\n",
    "        print('==== Failure To Retrieve ====')\n",
    "        print(data)\n",
    "        continue\n",
    "\n",
    "    # print(json.dumps(js, indent=4))\n",
    "\n",
    "    place_id = js['results'][0]['place_id']\n",
    "    print(f'Place id {place_id}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fde92839811899535f1980ad3dab24d92e157ba2c789293b3eeab787fcd034ff"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
